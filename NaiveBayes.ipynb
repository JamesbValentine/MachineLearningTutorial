{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce7294e",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "#### Ruixuan Dong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb7783",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    " - [The Naive Bayes classification algorithm](#1)\n",
    "    - [Algorithm Explanation](#11)\n",
    "    - [An Intuitive Explanation](#12)\n",
    " - [Research Problem -- Using synthetic data to classify different systolic levels](#2)\n",
    "    - [Overview of the Problem set](#21)\n",
    "    - [Implement Naive Bayes on Synthetic data](#22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67192b9",
   "metadata": {},
   "source": [
    "<a name='11'></a>\n",
    "### 1- The Naive Bayes classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7712f",
   "metadata": {},
   "source": [
    "In this section, we'll explain the Naive Bayes classification algorithm step by step.\n",
    "\n",
    "\n",
    "\n",
    "<a name='11'></a>\n",
    "#### 1-1 Algorithm Explanation\n",
    "\n",
    "The code provided defines a simple Naive Bayes classifier. Here's an overview of the key functions and their purpose:\n",
    "\n",
    " - `loadDataSet()`: This function defines a simple dataset of text messages and assigns binary labels (0 or 1) to each message. It returns two lists: `postingList` containing the text messages and `classVec` containing the corresponding labels.\n",
    " - `createVocabList(dataSet)`: This function takes the `postingList` and creates a vocabulary set by extracting unique words from all the text messages.\n",
    " - `setOfWords2Vec(vocabList, inputSet)`: This function takes a vocabulary list and a text message as input and converts the message into a binary vector. Each element of the vector corresponds to a word in the vocabulary, and a 1 indicates the presence of that word in the message.\n",
    " - `trainNB0(trainMatrix, trainCategory)`: This function performs the training of the Naive Bayes classifier. It calculates the probabilities of words given the class (either 0 or 1) and the probability of class 1 (`pAbusive`).\n",
    " - `classifyNB(vec2Classify, p0Vec, p1Vec, pClass1)`: This function classifies a new input vector (`vec2Classify`) based on the probabilities calculated during training. It computes the probability of the input vector belonging to class 1 and class 0 and returns the class with the higher probability.\n",
    " - `testingNB()`: This function demonstrates the classification by testing two example messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdeb455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0,1,0,1,0,1] \n",
    "    return postingList,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa11f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document) \n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5efc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else: print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOPosts,listClasses = loadDataSet()\n",
    "myVocabList = createVocabList(listOPosts)\n",
    "myVocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98952b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    numTrainDocs = len(trainMatrix)\n",
    "    numWords = len(trainMatrix[0])\n",
    "    pAbusive = sum(trainCategory)/float(numTrainDocs)\n",
    "    p0Num = np.zeros(numWords); p1Num = np.zeros(numWords)\n",
    "    p0Denom = 0.0; p1Denom = 0.0\n",
    "    for i in range(numTrainDocs):\n",
    "        if trainCategory[i] == 1:\n",
    "            p1Num += trainMatrix[i]\n",
    "            p1Denom += sum(trainMatrix[i])\n",
    "        else:\n",
    "            p0Num += trainMatrix[i]\n",
    "            p0Denom += sum(trainMatrix[i])\n",
    "    p1Vect = p1Num/p1Denom          #change to log()\n",
    "    p0Vect = p0Num/p0Denom          #change to log()\n",
    "    return p0Vect,p1Vect,pAbusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aaf4b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce  \n",
    "def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):\n",
    "    p1 = reduce(lambda x,y:x*y, vec2Classify * p1Vec) * pClass1 \n",
    "    p0 = reduce(lambda x,y:x*y, vec2Classify * p0Vec) * (1.0 - pClass1)\n",
    "    print('p0:',p0)\n",
    "    print('p1:',p1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1548780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingNB():\n",
    "    listOPosts,listClasses = loadDataSet()\n",
    "    myVocabList = createVocabList(listOPosts)\n",
    "    trainMat=[]\n",
    "    for postinDoc in listOPosts:\n",
    "        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
    "    p0V,p1V,pAb = trainNB0(np.array(trainMat),np.array(listClasses))\n",
    "    testEntry = ['love', 'my', 'dalmation']\n",
    "    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "    if classifyNB(thisDoc,p0V,p1V,pAb):\n",
    "        print(testEntry,'yes')\n",
    "    else:\n",
    "        print(testEntry,'no')\n",
    "    testEntry = ['stupid', 'garbage']\n",
    "    thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "    if classifyNB(thisDoc,p0V,p1V,pAb):\n",
    "        print(testEntry,'yes')\n",
    "    else:\n",
    "        print(testEntry,'no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "266adddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "listOPosts,listClasses = loadDataSet()\n",
    "myVocabList = createVocabList(listOPosts)\n",
    "myVocabList\n",
    "trainMat = []\n",
    "\n",
    "for postinDoc in listOPosts:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) \n",
    "    \n",
    "p0V,p1V,pAb=trainNB0(trainMat,listClasses)\n",
    "\n",
    "pAb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dade8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04166667, 0.04166667, 0.        , 0.04166667, 0.        ,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.        , 0.        ,\n",
       "       0.        , 0.08333333, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.        , 0.04166667, 0.04166667, 0.        , 0.        ,\n",
       "       0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "       0.04166667, 0.04166667, 0.        , 0.        , 0.125     ,\n",
       "       0.04166667, 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce4c59",
   "metadata": {},
   "source": [
    "The code defines and trains a Naive Bayes classifier on the provided dataset. It then classifies two test messages and prints the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b938547",
   "metadata": {},
   "source": [
    "<a name='12'></a>\n",
    "#### 1-2 An Intuitive Explanation\n",
    "\n",
    "\n",
    "Naive Bayes is a probabilistic algorithm used for classification. It works by calculating the probability that a given input belongs to each class and then choosing the class with the highest probability.\n",
    "\n",
    "In this specific implementation, we use text data, and the algorithm assumes that the words in the text are conditionally independent given the class label (hence \"naive\"). It calculates the probability of each word occurring in messages belonging to class 0 and class 1 during training.\n",
    "\n",
    "For example, if you have a message \"love my dalmatian,\" the algorithm calculates the probability of each word (\"love,\" \"my,\" \"dalmatian\") appearing in messages labeled 0 and 1. It uses these probabilities to classify new messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4ef55a",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "### 2 - Research Problem - Using Synthetic Data to Classify Different Systolic Levels\n",
    "\n",
    "<a name=\"21\"></a>\n",
    "#### 2-1 Overview of the Problem Set\n",
    "\n",
    "In this section, you can introduce the problem you're trying to solve with Naive Bayes classification. You might want to replace \"systolic levels\" with the actual problem you're addressing. Describe the dataset and the problem statement.\n",
    "\n",
    "**Problem Statement:** The generated dataset containing: \n",
    "- a dataset set (\"total_large.csv\") of 6,000 samples labeled as lower (100<=systolic blood pressure<140) or higher (140<=systolic blood pressure<=160) \n",
    "- each sample is of shape (1, 1003) where 1003 is for the 1000-d signal and heart rate, respiratory rate and diastolic blood pressure\n",
    "\n",
    "In this part, we will build a simple Naive Bayes classifier that can correctly classify samples as lower or higher (SBP).\n",
    "\n",
    "Let's get more familiar with the dataset. Load the data by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "355cba86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.439234e-08</td>\n",
       "      <td>2.583753e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-4.897503e-07</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-2.029141e-07</td>\n",
       "      <td>3.029687e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.750468e-08</td>\n",
       "      <td>-3.504179e-08</td>\n",
       "      <td>-3.266654e-08</td>\n",
       "      <td>-2.969555e-08</td>\n",
       "      <td>-2.688206e-08</td>\n",
       "      <td>-2.599564e-08</td>\n",
       "      <td>109.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.781177e-08</td>\n",
       "      <td>3.850786e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-3.642447e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.308896e-07</td>\n",
       "      <td>-1.850758e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.937486e-08</td>\n",
       "      <td>-3.615418e-08</td>\n",
       "      <td>-3.250324e-08</td>\n",
       "      <td>-2.930146e-08</td>\n",
       "      <td>-2.813366e-08</td>\n",
       "      <td>-2.915194e-08</td>\n",
       "      <td>131.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.434446e-08</td>\n",
       "      <td>2.098668e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-1.939304e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-9.990558e-07</td>\n",
       "      <td>3.452373e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.199401e-08</td>\n",
       "      <td>-2.472291e-08</td>\n",
       "      <td>-1.890941e-08</td>\n",
       "      <td>-1.882332e-08</td>\n",
       "      <td>-2.188260e-08</td>\n",
       "      <td>-2.335538e-08</td>\n",
       "      <td>128.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1             2         3         4         5         6  \\\n",
       "0  5.439234e-08  2.583753e-07  0.000001  0.000004  0.000008  0.000006   \n",
       "1  5.781177e-08  3.850786e-07  0.000002  0.000007  0.000007 -0.000001   \n",
       "2  3.434446e-08  2.098668e-07  0.000003  0.000006 -0.000003  0.000002   \n",
       "\n",
       "              7         8             9            10  ...           995  \\\n",
       "0 -4.897503e-07 -0.000004 -2.029141e-07  3.029687e-06  ... -3.750468e-08   \n",
       "1 -3.642447e-06  0.000002  8.308896e-07 -1.850758e-06  ... -3.937486e-08   \n",
       "2 -1.939304e-06  0.000001 -9.990558e-07  3.452373e-07  ... -3.199401e-08   \n",
       "\n",
       "            996           997           998           999          1000  \\\n",
       "0 -3.504179e-08 -3.266654e-08 -2.969555e-08 -2.688206e-08 -2.599564e-08   \n",
       "1 -3.615418e-08 -3.250324e-08 -2.930146e-08 -2.813366e-08 -2.915194e-08   \n",
       "2 -2.472291e-08 -1.890941e-08 -1.882332e-08 -2.188260e-08 -2.335538e-08   \n",
       "\n",
       "   heart_rate  respiratory_rate  systolic  diastolic  \n",
       "0       109.0              19.0     160.0       66.0  \n",
       "1       131.0              15.0     153.0       64.0  \n",
       "2       128.0              14.0     120.0       85.0  \n",
       "\n",
       "[3 rows x 1004 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column_names = [str(i) for i in range(1, 1001)] + ['heart_rate', 'respiratory_rate', 'systolic', 'diastolic']\n",
    "total = pd.read_csv('total_large.csv', \n",
    "                     header=None, \n",
    "                     names=column_names)\n",
    "total.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25e674e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal2matrix(total):\n",
    "    total = total.values\n",
    "\n",
    "    numberOfLines = len(total)\n",
    "    returnMat = np.zeros((numberOfLines, 1003))\n",
    "    classLabelVector = []\n",
    "    index = 0\n",
    "\n",
    "    for line in total:\n",
    "        returnMat[index, :1002] = line[:1002]\n",
    "        returnMat[index, 1002] = line[1003]\n",
    "        if 100 <=line[1002]< 140:\n",
    "            classLabelVector.append(1)\n",
    "        elif 140 <=line[1002]<= 160:\n",
    "            classLabelVector.append(2)\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "012c9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalDataMat,signalLabels = signal2matrix(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bccc9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoNorm(dataSet):\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normDataSet = np.zeros(np.shape(dataSet))\n",
    "    m = dataSet.shape[0]\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet / np.tile(ranges, (m, 1))\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "829b27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "normMat, ranges, minVals = autoNorm(signalDataMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5eb66",
   "metadata": {},
   "source": [
    "<a name='22'></a>\n",
    "#### 2-2Implement Naive Bayes on Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7494e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal2matrix(total):\n",
    "    total = total.values\n",
    "\n",
    "    numberOfLines = len(total)\n",
    "    featureMatrix = np.zeros((numberOfLines, 1002))\n",
    "    classLabelVector = []\n",
    "\n",
    "    for index, line in enumerate(total):\n",
    "        featureMatrix[index, :] = line[:1002]\n",
    "        classLabel = line[1002]\n",
    "        if 100 <= classLabel < 140:\n",
    "            classLabelVector.append(1)\n",
    "        elif 140 <= classLabel <= 160:\n",
    "            classLabelVector.append(2)\n",
    "\n",
    "    return featureMatrix, classLabelVector\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have loaded your dataset into 'total'\n",
    "X, y = signal2matrix(total)\n",
    "\n",
    "# Split the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming you have already defined the Naive Bayes functions\n",
    "\n",
    "# Train the Naive Bayes classifier on the training data\n",
    "p0V, p1V, pAb = trainNB0(X_train, y_train)\n",
    "\n",
    "# Optionally, you can print the class probabilities\n",
    "print('p0V:', p0V)\n",
    "print('p1V:', p1V)\n",
    "print('pAb:', pAb)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already trained the classifier\n",
    "y_pred = []\n",
    "\n",
    "for x in X_test:\n",
    "    thisDoc = np.array(x)\n",
    "    class_label = classifyNB(thisDoc, p0V, p1V, pAb)\n",
    "    y_pred.append(class_label)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
